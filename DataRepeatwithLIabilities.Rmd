---
title: "Data Analysis for Demand During Crises"
author: "Ryan Martin"
date: "June 2, 2020"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE)
knitr::opts_chunk$set(message = FALSE)
knitr::opts_chunk$set(warning = FALSE)
knitr::opts_chunk$set(tidy.opts=list(width.cutoff=80),tidy=TRUE)
knitr::opts_chunk$set(cache = TRUE)
# Original saved in C:\Users\mrya\Desktop\BNDS\Analysis\WithdrawalDepositCovidAnalysis
```

# Read In Data

```{r readindata, echo = FALSE}
# Reading in the data

library(pacman)
p_load(here, haven, tidyverse, ggplot2,sjlabelled, lubridate, 
  readxl, gapminder, kableExtra, RColorBrewer,zoo, astsa)
my_folder <- here("data")
my_tex_folder = here("LiabilitiesFigures")  

datliabl=read_csv(paste(my_folder, "NICTimeSeriesfromLiabilities.csv" , sep="/"))
# view(datliabl)
datliabl = datliabl %>% rename(NIC = `NIC-Liabilities`)
datliabl = datliabl %>% rename(NIC_Mills = `NIC-Liabilities-Mils`)
datliabl = datliabl %>% mutate(net_withdrawal = NIC - lag(NIC))
datliabl = datliabl %>% mutate(year_mon = as.yearmon(date)) %>% mutate( week = week(date))

filter = dplyr::filter
financial_events <- tibble(
  date = as_date(c("2020-03-12",
     "2008-09-01", "2009-09-01", #Lehman Bankruptcy to 2000 ARRA (American Recovery and Reinvestment Act) could also use March 6 2009 as nadar of down jones as end
     "2001-09-01", "2002-01-01",
     "1998-10-01", "2000-01-01", #Year 2000 Information and Readiness Disclosure Act to start of new year
     "1998-01-04", "1998-03-01" #Ice storm start is January 4th when formed. End was unclear. The power outage lasted several weeks for some places, or even several months. https://en.wikipedia.org/wiki/January_1998_North_American_ice_storm
     )),
  Event_Name = c("Pandemic start", 
    "GFC start", "GFC end",
    "Sept 11 start", "Sept 11 end",
    "Y2K start", "Y2K end",
    "Ice Storm start", "Ice Storm end"
))

datagg = datliabl
```


```{r}

# TS Analysis
ts_dat = ts(datagg)
# View(ts_dat)
plot(ts_dat)
# it looks like net_withdrawal is more stable
# than weekly nic percent change

# should be mean, not sum? or sum of Change in NIC
datagg = datagg %>% mutate(year = year(date))
datagg = datagg %>% filter(year >= 1998) %>% filter( year <=2020 )
dataggtemp = datagg %>% mutate(
  Quarter = as.numeric(quarter(date)), Year_Quarter = year + (Quarter-1)/4) %>% ungroup() %>% group_by(Year_Quarter) %>%
  summarise(NIC_quarter = mean(NIC))


simple_ts = datagg %>% select(net_withdrawal)
simple_ts = ts(simple_ts)#ts(simple_ts, start = datagg$date[1], end=datagg$date[nrow(datagg)])
plot(simple_ts)

###### Adding in CPI Data
CPIdat = read_csv(file=paste(my_folder, "CPIMonthlyUnadjusted1998to2020.csv", sep="/"))
CPIdat = CPIdat %>% mutate(year_month = as.yearmon(Date))


# Bringing in nominal GDP Data
GDPdat = read_csv(file=paste(my_folder, "NominalGDP1998to2020.csv", sep="/"))
# GDPdat
names(GDPdat) = c("GDP", "date", "Consumption", "Population")
GDPdat = GDPdat %>% separate(date, into = c("Quarter", "Year"),
    sep=" ", remove=FALSE) %>% mutate(year = as.numeric(Year),
        Consumption = Consumption*10^6) %>%
    separate(Quarter, into= c("Q","Quarter_Num"), 
      sep = "Q" ) %>% 
    select(-Q) %>% mutate(Quarter_Frac = 
      year + (as.numeric(Quarter_Num) - 1)/4) %>%
  mutate(GDP = GDP*1e6)




# plot
ggplot(GDPdat, aes(x=Quarter_Frac, y = GDP/10)) + geom_line() +
  geom_line(data=dataggtemp, aes(x=Year_Quarter, y =
        NIC_quarter), color="red")

ggplot(GDPdat, aes(x=Quarter_Frac, y = Consumption/10)) + geom_line() +
  geom_line(data=dataggtemp, aes(x=Year_Quarter, y =
        NIC_quarter), color="red")


datagg = datagg %>% filter(year >= 1988)


```

```{r}
# How much did NIC go up per person?

# in 2016, 14.1 million private houseeholds
# https://www150.statcan.gc.ca/n1/daily-quotidien/170913/t001a-eng.htm

net_withdrawal_per_person_2020 = 
  datagg %>% filter(year>=2020) %>% 
  mutate(NIC_per_capita = NIC/(37.59*1e6),
      net_withdrawal_per_capita = net_withdrawal/(37.59*1e6),
      NIC_per_hhld = NIC/(14.1*1e6),
      net_withdrawal_per_hhld = net_withdrawal/(14.1*1e6)
      )

summary_net_withdrawal_per_person_2020 = net_withdrawal_per_person_2020 %>% filter(week>=7) %>%
  select(date, week, NIC_per_capita, NIC_per_hhld, net_withdrawal_per_capita, net_withdrawal_per_hhld)


view(summary_net_withdrawal_per_person_2020)


summary_net_withdrawal_per_person_2020 %>% 
  filter(date == "2020-02-12"| date == "2020-06-17") %>%
  select(NIC_per_hhld)
6981-6332
# it's a large number, but NIC per person is also large enough that interpreting these numbers should be done with caution.

# vs 2001 population 31.02 million, 11561, 975
# https://www12.statcan.gc.ca/English/census01/products/standard/themes/Rp-eng.cfm?LANG=E&APATH=3&DETAIL=0&DIM=0&FL=A&FREE=0&GC=0&GID=0&GK=0&GRP=1&PID=55708&PRID=0&PTYPE=55430,53293,55440,55496,71090&S=0&SHOWALL=0&SUB=0&Temporal=2001&THEME=54&VID=0&VNAMEE=&VNAMEF=


```


Looking at the periodogram, what can we conclude?

Notice that as we move farther right, the frequency gets larger, which means the period gets shorter. In particular, as we move to the write, $\omega = 1/2$ corresponds to a period of $T = 2$ data points. That is, cycles that last two steps long. A period that is infinite means we don't see a full cycle in our data. This means that T>n. 1 Year has a freqeuncy of 1/52. We see that there is a spike here, as well as at harmonics of 1 year, $k/52$ for $k = 2,3, ..., 12$. The harmonics arise because each annual cycle is not perfect sinusoidal behavior.


```{r}

#periodogram
p_load(astsa)
simple_ts = simple_ts[!is.na(simple_ts)]
dat.per = mvspec(simple_ts, log="n") #n.used=1200, roughly 23 years


year_harmonics = 1:15/52
year_multiples = as.character(1:15)#paste("Year Harmonic", as.character(1:12), sep = " ")
year_harmonic_tib = tibble(year_harmonics, year_multiples)

dat4plot= tibble(frequency = dat.per$freq, spectogram = dat.per$spec)
ggplot(dat4plot) + geom_line(aes(x=frequency, y =spectogram)) +
  geom_vline(xintercept = year_harmonics, color= year_multiples) +
  ggtitle("Periodogram of Net Withdrawals 1998-2020 with Colored Year Harmonics")
ggsave( paste("RawNoteWithdrawalPeriodogramWithColors.jpg", sep = ""),
    path = paste(my_tex_folder, "weekly", sep = "/"))


ggplot(dat4plot) + geom_line(aes(x=frequency, y =spectogram)) + ggtitle("Tapered Periodogram of Net Withdrawals 1998-2020")
ggsave( paste("RawNoteWithdrawalPeriodogramNoColors.jpg", sep = ""),
    path = paste(my_tex_folder, "weekly", sep = "/"))



# adding a taper
#periodogram
dat.per.taper = mvspec(simple_ts, taper=.1, log="no") #n.used=1200, roughly 23 years


dat4plottaper= tibble(frequency = dat.per.taper$freq, spectogram = dat.per.taper$spec)
ggplot(dat4plottaper) + geom_line(aes(x=frequency, y =spectogram)) +
  geom_vline(xintercept = year_harmonics, color= year_multiples) + ggtitle("Tapered Periodogram With Colored, 1-Year Harmonics")
ggsave( paste("RawNoteWithdrawalPeriodogram.jpg", sep = ""),
    path = paste(my_tex_folder, "weekly", sep = "/"))

dat4plottaper= tibble(frequency = dat.per.taper$freq, spectogram = dat.per.taper$spec)
ggplot(dat4plottaper) + geom_line(aes(x=frequency, y =spectogram))


#looking at logged version. not very helpful
dat.perlog = mvspec(simple_ts, log="yes") #n.used=1200, roughly 23 years



#Extracting Annual Frequency signal
SigExtract(simple_ts, L =9, M =64, max.freq =1/52) # I don't know how good the filtered series is

```



Note that the Ljung-Box statistic is a measure of the sum of the autocorrelation of the errors up to lag H. Values below the dotted line suggest there is still auto-correlation left in the errors. 

```{r}
# SARIMA Modeling

# Note that one year is 365/7 = 52 1/7 or 366/7 = 52 2/7 weeks
graphics.off
simple_ts_scale= simple_ts/1e8

graphics.off()
acf2(simple_ts_scale,max.lag = 60)
# clearly, the first few lags matter and the lags around
# 50, 52, 53 also matter

# recall its ARIMA(p,d,q) x (P,D,Q)_s
# So lets try(2,0,1) x (1,0,1)_{52}
model0 = sarima(simple_ts_scale,p=2,d=0,q=1,
    P=1,D=0,Q=1,S=52)
# the autocorrelation is very bad in the errors
# not capturing it all very well

graphics.off()
# model1 = sarima(simple_ts_scale,p=10,d=0,q=5,
#    P=1,D=0,Q=1,S=52) 
# breaks

# sarima models don't work that well for this data
# try nonparametric regression
datagg_short = datagg %>% filter(date<="2020-02-01")
table(datagg_short$week)
reg1_out = lm(data=datagg_short, formula=net_withdrawal ~ as.factor(week) + year + I(exp(year/1000)) )
reg1_out_no_inter = lm(data=datagg_short, formula=net_withdrawal ~ as.factor(week) + year + I(year^2))
p_load(jtools)
summ(reg1_out)
summ(reg1_out_no_inter)
# interesting to note how reg1_out_no_inter vs reg1_out have totally
# different levels of significant for the coefficients. without
# the intercept, week intercepts picks up average week level

logdat = datagg%>% mutate(log_net_lag_nic = log(NIC/lag(NIC)))
reg_log_out = lm(data=logdat, formula=log_net_lag_nic ~ week + year + I(year^2))
plot(reg_log_out) #residuals for this seem much wakier
plot(reg1_out)
p_load(BETS, jtools, ggstance, broom, broom.mixed)
plot_summs(reg1_out)
week_names = paste("Week", as.character(2:53), sep = " ")
names(reg1_out$coefficients) = c("Intercept", week_names, "year", "(year)^2")
summ(reg1_out)
summ(reg_log_out)

#gam_out = gam::gam(data=datagg_short, formula= NIC ~ as.factor(week) + lo(year,span=.6))

#attach(datagg_short)
#spm_out = SemiPar::spm(NIC ~ as.factor(week) + f(year))
#gam_pred = stats::predict(gam_out, datagg)
#gam_pred
plot_summs(reg1_out, omit.coefs = c("Intercept", "year","(year)^2" ), ci_level = .95) + ggtitle("Weekly Fixed Effects")

######################
# Try forecasted vs true as nic
my_forecast = stats::predict(reg1_out, newdata=datagg)
forecast_nic =  tibble(date=datagg$date, fitted_net_withdrawal = my_forecast) %>% mutate(fitted_nic = cumsum(fitted_net_withdrawal))

datagg=datagg %>% mutate(Year = as_character(year))
netwithdrawal_pred_1999= broom::augment(reg1_out, newdata= datagg %>% filter(year==2019))
ggplot(netwithdrawal_pred_1999, aes(x = date, y = .fitted)) + geom_line() + geom_line(data=netwithdrawal_pred_1999,
  aes(x=date, y = net_withdrawal), color="red") + ylab("Net Withdrawal") + 
  ggtitle("Predicted Net Withdrawal in Red vs True for 1999")
ggsave( paste("PredictedvsTrueNetWithdrawal1999.jpg", sep = ""),
    path = paste(my_tex_folder, "weekly", sep = "/"))



datagg = datagg %>% mutate(week = as.numeric(week))
ggplot(datagg, aes(x=week, y = net_withdrawal, color=Year ))+ 
  geom_point()  + 
  geom_line(data = netwithdrawal_pred_1999, aes(x = week, y = .fitted), size=1.5, color="black" ) + ylab("Net Withdrawal (Millions CAD)") +
  ggtitle("Seasonally Predicted 1999 vs True Net Withdrawals All Years")
ggsave( paste("PredictedvsTrueNetWithdrawalAllYears.jpg", sep = ""),
    path = paste(my_tex_folder, "weekly", sep = "/"))

true_and_forecast = left_join(datagg, forecast_nic)

gap = true_and_forecast$NIC[1] - true_and_forecast$fitted_nic[1]
true_and_forecast = true_and_forecast %>% mutate(
  fitted_nic_cor = fitted_nic + gap)
ggplot(true_and_forecast, aes(x=date, y = fitted_nic_cor)) + geom_point() + geom_point(aes(x=date, y = NIC), color="red") + 
  ggtitle("Seasonal Fit to Notes in Circulation Data: True in Red, Forecast in Black")
ggsave( paste("SeasonalFitToNIC.jpg", sep = ""),
    path = paste(my_tex_folder, "weekly", sep = "/"))


p_load(lme4)
p_load(splines)
p_load(nlme)
datagg_short = datagg_short %>% mutate(Week = as_factor(week))
#fit1 <- lme(NIC ~ bs(year,df=3),random =  ~1|Week,method="ML", data=datagg_short)
# summary(fit1)

p_load(earth)
fit1 <- earth(net_withdrawal ~ year + Week, data=datagg_short,pmethod="none")
summary(fit1)


my_knots = quantile(datagg$year, p = c(.5))
fit2 = lm(net_withdrawal~bs(year, knots=my_knots) + Week, data=datagg_short) 
summary(fit2)




datagg = datagg %>% mutate(Week = as_factor(week)) 
# Try forecasted vs true as nic
my_forecast2 = stats::predict(fit1, newdata=datagg)
forecast_nic_spline =  tibble(date=datagg$date, fitted_net_withdrawal = my_forecast2) %>% mutate(fitted_nic = cumsum(fitted_net_withdrawal))

datagg=datagg %>% mutate(Year = as_character(year))
netwithdrawal_pred_1999_spl= datagg %>% filter(year==2019) %>% cbind(tibble( .fitted =  stats::predict(fit1, newdata=datagg %>% filter(year==2019))))
ggplot(netwithdrawal_pred_1999_spl, aes(x = date, y = .fitted)) + geom_line() + geom_line(data=netwithdrawal_pred_1999_spl,
  aes(x=date, y = net_withdrawal), color="red") + ylab("Net Withdrawal") + 
  ggtitle("Predicted Net Withdrawal in Red vs True for 1999")
ggsave( paste("PredictedvsTrueNetWithdrawal1999spl.jpg", sep = ""),
    path = paste(my_tex_folder, "weekly", sep = "/"))


####################
# Now with Knotted
#####################

my_forecast2 = stats::predict(fit2, newdata=datagg)
forecast_nic_spline =  tibble(date=datagg$date, fitted_net_withdrawal = my_forecast2) %>% mutate(fitted_nic = cumsum(fitted_net_withdrawal))

datagg=datagg %>% mutate(Year = as_character(year))
netwithdrawal_pred_1999_spl= broom::augment(fit2, newdata= datagg %>% filter(year==2019))
ggplot(netwithdrawal_pred_1999_spl, aes(x = date, y = .fitted)) + geom_line() + geom_line(data=netwithdrawal_pred_1999_spl,
  aes(x=date, y = net_withdrawal), color="red") + ylab("Net Withdrawal") + 
  ggtitle("Predicted Net Withdrawal in Red vs True for 1999")
ggsave( paste("PredictedvsTrueNetWithdrawal1999spl2.jpg", sep = ""),
    path = paste(my_tex_folder, "weekly", sep = "/"))



datagg = datagg %>% mutate(week = as.numeric(week))
ggplot(datagg, aes(x=week, y = net_withdrawal, color=Year ))+ 
  geom_point()  + 
  geom_line(data = netwithdrawal_pred_1999_spl, aes(x = week, y = .fitted), size=1.5, color="black" ) + ylab("Net Withdrawal (Millions CAD)") +
  ggtitle("Seasonally Predicted 1999 vs True Net Withdrawals All Years")
ggsave( paste("PredictedvsTrueNetWithdrawalAllYearsspl2.jpg", sep = ""),
    path = paste(my_tex_folder, "weekly", sep = "/"))

true_and_forecast_spl = left_join(datagg, forecast_nic_spline)

gap_spl = true_and_forecast_spl$NIC[1] - true_and_forecast_spl$fitted_nic[1]
true_and_forecast_spl = true_and_forecast_spl %>% mutate(
  fitted_nic_cor = fitted_nic + gap)
ggplot(true_and_forecast_spl, aes(x=date, y = fitted_nic_cor)) + geom_point() + geom_point(aes(x=date, y = NIC), color="red") + 
  ggtitle("Seasonal Fit to Notes in Circulation Data: True in Red, Forecast in Black")
ggsave( paste("SeasonalFitToNICspl2.jpg", sep = ""),
    path = paste(my_tex_folder, "weekly", sep = "/"))




```


```{r}
 
p_load(lme4, splines, nlme, earth,jtools)
#datagg = datagg %>% mutate(Week = as_factor(month))
datagg = datagg %>% drop_na()
fit1 <- earth(net_withdrawal ~ year + Week, data=datagg,pmethod="none")
summary(fit1)


my_knots = quantile(datagg$year, p = c(.5))
fit2 = lm(net_withdrawal~bs(year, knots=my_knots) + Month, data=datagg) 
summary(fit2)


my_forecast2 = stats::predict(fit1, newdata=datagg)
forecast_nic_spline =  tibble(date=datagg$date, fitted_net_withdrawal = my_forecast2) %>% mutate(fitted_nic = cumsum(fitted_net_withdrawal))


####################
# Now with Knotted
#####################

week_names = paste("Week", as.character(2:53), sep = "")

gen_plots <- function(my_model, my_name) {
  
  if( class(my_model)=="earth") {
    temp = row.names(my_model$coefficients)
    omit_these_coefs = rep("name", length(temp) - 52)
    count = 1
    for (my_coef_name in temp) {
      if (!isTRUE(as.logical(grep(pattern="Week", my_coef_name)))) {
        omit_these_coefs[count] = my_coef_name
        count = count + 1
      }
    }
  } else {
    temp = names(my_model$coefficients)
    omit_these_coefs = rep("name", length(temp) - 52)
    count = 1
    for (my_coef_name in temp) {
      if (!isTRUE(as.logical(grep(pattern="Week", my_coef_name)))) {
        omit_these_coefs[count] = my_coef_name
        count = count + 1
      }
    }
  }
  if (class(my_model)!="earth") {
    # earth package does not play well with other model output packages. too bad
    # looks like just calls (tidy(my_model))...)
  plot1 = jtools::plot_summs(my_model, omit.coefs = omit_these_coefs,
    ci_level = .95) + ggtitle("Weekly Fixed Effects")
  plot1
  ggsave( paste("WeeklyCoefficientPlot", my_name, ".jpg", sep = ""),
      path = paste(my_tex_folder, "weekly", sep = "/"))
  } else {
  plot1 = ggplot(tibble(coef_names = names(
    my_model$coefficients[!(row.names(my_model$coefficients) %in% omit_these_coefs), ]),
    coef_values = my_model$coefficients[!(row.names(my_model$coefficients) %in% 
      omit_these_coefs), ]),
      aes(x = coef_names, y = coef_values)) + geom_point() + 
    ggtitle("Weekly Fixed Effects") + xlab("Week") + ylab("Millions CAD")
  plot1
  ggsave( paste("WeeklyCoefficientPlot", my_name, ".jpg", sep = ""),
      path = paste(my_tex_folder, "weekly", sep = "/"))
  }
  
  my_forecast = stats::predict(my_model, newdata=datagg)
  forecast_nic_func =  tibble(date=datagg$date, 
    fitted_net_withdrawal = my_forecast) %>% 
    mutate(fitted_nic = cumsum(fitted_net_withdrawal))
  
  #netwithdrawal_pred_1999_spl= datagg %>% 
  #  mutate(.fitted = my_model$fitted.values) %>% 
  #  filter(year == 2019)

  netwithdrawal_pred_1999_spl= datagg %>% 
    mutate(.fitted = my_forecast) %>% 
    filter(year == 2019)
  
  plot2 = ggplot(netwithdrawal_pred_1999_spl, aes(x = date, y = .fitted)) + 
    geom_line() + geom_line(data=netwithdrawal_pred_1999_spl,
    aes(x=date, y = net_withdrawal), color="red") + ylab("Net Withdrawal") + 
    ggtitle("Predicted Net Withdrawal in Red vs True for 1999")
  plot2 
  ggsave( paste("PredictedvsTrueNetWithdrawal1999", my_name, ".jpg", sep = ""),
      path = paste(my_tex_folder, "weekly", sep = "/"))
  
  
  plot3 = ggplot(datagg, aes(x = week, y = net_withdrawal, color=Year ))+ 
    geom_point()  + 
    geom_line(data = netwithdrawal_pred_1999_spl, aes(x = week, y = .fitted),
      size=1.5, color="black" ) + ylab("Net Withdrawal (Millions CAD)") +
    ggtitle("Seasonally Predicted 2019 vs True Net Withdrawals All Years")
  plot3
  ggsave( paste("PredictedvsTrueNetWithdrawalAllYears", my_name, 
    ".jpg", sep = ""),
    path = paste(my_tex_folder, "weekly", sep = "/"))
  
  true_and_forecast_spl = left_join(datagg, forecast_nic_func)
  gap_spl2 = true_and_forecast_spl$NIC[1] - true_and_forecast_spl$fitted_nic[1]
  true_and_forecast_spl = true_and_forecast_spl %>% mutate(
    fitted_nic_cor = fitted_nic + gap)
  plot4 = ggplot(true_and_forecast_spl, aes(x=date, y = fitted_nic_cor)) + 
    geom_point() + geom_point(aes(x=date, y = NIC), color="red") +
    ggtitle("Seasonal Fit to Notes in Circulation Data: True in Red, Forecast in Black")
  plot4
  ggsave( paste("SeasonalFitToNICspl", my_name, ".jpg", sep = ""),
      path = paste(my_tex_folder, "weekly", sep = "/"))
  return(list(plot1, plot2, plot3, plot4))
}


myfirstlist = gen_plots(fit1,"earth_model") 
mysecondlist = gen_plots(fit2,"one_knot_splines")
myfirstlist[1]
myfirstlist[2]
myfirstlist[3]
mysecondlist[1]
mysecondlist[2]
mysecondlist[3]
mysecondlist[4]



```


```{r}
# Now, working on the residuals
# Obviously, don't interpret any of the coefficients too literally
# from here on out because already used some degrees of freedom

# Choosing spline model
reg1_out = fit2
simple_ts_fit = ts(reg1_out$residuals)

#periodogram
dat.per = mvspec(simple_ts_fit, log="no") #n.used=1200, roughly 23 years



# adding a taper
#periodogram
dat.per.taper = mvspec(simple_ts_fit, taper=.1, log="no")
dat4plottaper= tibble(frequency = dat.per.taper$freq, spectogram = dat.per.taper$spec)
ggplot(dat4plottaper) + geom_line(aes(x=frequency, y =spectogram)) +
  geom_vline(xintercept = year_harmonics, color= year_multiples) + ggtitle("Tapered Periodogram With Colored, 1-Year Harmonics")


# now redoing the sarima
# recall its ARIMA(p,d,q) x (P,D,Q)_s
# So lets try(2,0,1) x (1,0,1)_{52}
acf2(simple_ts_fit) # looks like just seasonal left

acf2(simple_ts_fit,max.lag = 60)
model2 = sarima(simple_ts_fit,5,0,5,no.constant = TRUE) # 
  # some of the AR and MA terms are significant
  # annoying it won't give

model3 = sarima(simple_ts_fit,3,0,2,no.constant = TRUE)
  # none of the terms here are that significant

k=4
# Detecting large values in residuals
threshold = k*var(model2$degrees_of_freedom)
ts_out =arima(simple_ts_fit, order=c(3,0,2),include.mean = FALSE)
plot(ts_out$residuals)
acf2(ts_out$residuals)


# Detecting large values in residuals
k=4
threshold = k*sd(simple_ts_fit)
large_resid = which(abs(simple_ts_fit) > threshold)
datagg$date[large_resid]

# what about *persistent positive sequences?


resid_tab = tibble(date=datagg_short$date,
  resid=as.numeric(simple_ts_fit))
resid_tab = resid_tab %>% mutate(fivelagsum =    
  resid+dplyr::lag(resid,n=1) +
  dplyr::lag(resid,n=2) + dplyr::lag(resid,n=3) +
    dplyr::lag(resid,n=4) + dplyr::lag(resid,n=5),
  fourlagsum = resid+dplyr::lag(resid,n=1) +
  dplyr::lag(resid,n=2) + dplyr::lag(resid,n=3) +
    dplyr::lag(resid,n=4),
  threelagsum = resid+dplyr::lag(resid,n=1) +
  dplyr::lag(resid,n=2) + dplyr::lag(resid,n=3),
  twolagsum = resid+dplyr::lag(resid,n=1) +
  dplyr::lag(resid,n=2),
  onelagsum = resid+dplyr::lag(resid,n=1) +
  dplyr::lag(resid,n=2))

my_paired_colors = brewer.pal(n = 12, "Paired")
quick_color = my_paired_colors[c(6,5,2,1,10,4,3,7,8)]


# here you really see 2000 and 2020 stand out
ggplot(resid_tab, aes(x=date, y = fivelagsum)) + geom_point() +
  ggtitle(" Cumulative Summation of Residual and Lags up to Five vs Date") +
  geom_vline(data= financial_events, 
    aes( xintercept = date, label = Event_Name, 
      color = Event_Name), wt = 3.5 ) + 
  scale_color_manual(values = quick_color) + ylab("")
ggsave( paste("FiveLagSum.jpg", sep = ""),
    path = paste(my_tex_folder, "weekly", sep = "/")) 

ggplot(resid_tab, aes(x=date, y = fourlagsum)) + geom_point() +
  ggtitle(" Cumulative Summation of Residual and Lags up to Fourth vs Date")
ggsave( paste("FourLagSum.jpg", sep = ""),
    path = paste(my_tex_folder, "weekly", sep = "/"))

ggplot(resid_tab, aes(x=date, y = threelagsum)) + geom_point()+
  ggtitle(" Cumulative Summation of Residuals and Lags up to Third vs Date")
ggsave( paste("ThreeLagSum.jpg", sep = ""),
    path = paste(my_tex_folder, "weekly", sep = "/"))

ggplot(resid_tab, aes(x=date, y = twolagsum)) + geom_point()+
  ggtitle(" Cumulative Summation of Residuals and Lag up to Second vs Date")
ggsave( paste("TwoLagSum.jpg", sep = ""),
    path = paste(my_tex_folder, "weekly", sep = "/"))


ggplot(resid_tab, aes(x=date, y = onelagsum)) + geom_point() +
  ggtitle(" Cumulative Summation of Residual and One Residual Lag vs Date")  +
  geom_vline(data= financial_events, 
    aes( xintercept = date, label = Event_Name, 
      color = Event_Name), wt = 3.5 ) + 
  scale_color_manual(values = quick_color) + ylab("")
ggsave( paste("OneLagSum.jpg", sep = ""),
    path = paste(my_tex_folder, "weekly", sep = "/"))



# here you really see 2000 and 2020 stand out
ggplot(resid_tab, aes(x=date, y = resid)) + geom_point() +
  ggtitle("Residuals After Controlling for Seasonal Effects vs Date") +
  geom_vline(data= financial_events, 
    aes( xintercept = date, label = Event_Name, 
      color = Event_Name), wt = 3.5 ) + 
  scale_color_manual(values = quick_color) + ylab("")
ggsave( paste("ResidualsAfterSeasonalAdj.jpg", sep = ""),
    path = paste(my_tex_folder, "weekly", sep = "/")) 


p_load(stargazer)
stargazer(reg1_out)

```


```{r}
acf2(simple_ts_fit^2)
Seasonal_Residuals=simple_ts_fit
acf2(Seasonal_Residuals,max.lag = 60)
Square_Of_Seasonal_Residuals = simple_ts_fit^2
acf2(Square_Of_Seasonal_Residuals)
# Looks pretty autocorrelated! I should fit a GARCH here just to see!
simple_ts_fit.sq = simple_ts_fit^2/(1e16)
simple_ts_fit_scale = simple_ts_fit/1e8
p_load(xts, fGarch)
# note that the arima modeling fails very poorly when numbers
# are large! hessian matrix fails. had to scale by 1e16 to 
# get it to evaluate. once scale, works well.
arima.fit.sq = arima(simple_ts_fit.sq + 0, order=c(3,0,0))
 #ar(1) and ar(3) are significant

out.garch <- garchFit(~ arma(1,0) + garch(3,1) , data=simple_ts_fit_scale, cond.dist="std") 
plot(out.garch)
summary(out.garch) # looks ok, but lots of NAs


# this one looks pretty good!
out.garch2 <- garchFit(~ arma(3,0) + garch(3,0) , data=simple_ts_fit_scale, cond.dist="std") 
plot(out.garch2) 
summary(out.garch2) # only issue is AR(3) not signif
 # and GARCh higher than one not significant. try simpler model



# this one looks pretty good!
out.garch2.5 <- garchFit(~ arma(2,0) + garch(1,0) , data=simple_ts_fit_scale, cond.dist="std") 
plot(out.garch2.5) 
summary(out.garch2.5) #looks ok


out.garch3 <- garchFit(~ arma(1,1) + garch(1,0) , data=simple_ts_fit_scale, cond.dist="std") #keep getting 
summary(out.garch3) #fit here much better! all terms highly signif.
plot(out.garch3) # looks about same as AR(3)


# Trying a heavier MA model
out.garch4 <- garchFit(~ arma(1,3) + garch(1,3) , data=simple_ts_fit_scale, cond.dist="std") #keep getting 
summary(out.garch4) # the heavier MA is not significant at all
  # for GARCh part. looks fine for rest. should reduce ma in
  # garch
plot(out.garch4)



# Trying a heavier MA model
out.garch5 <- garchFit(~ arma(2,3) + garch(2,0) , data=simple_ts_fit_scale, cond.dist="std") 
summary(out.garch5) #starting to get some errors in this
plot(out.garch5)


out.garch6.5 <- garchFit(~ arma(1,3) + garch(2,0) , data=simple_ts_fit_scale, cond.dist="std") 
summary(out.garch6.5) # garch(1,0) probably better
plot(out.garch6.5)


out.garch6 <- garchFit(~ arma(1,3) + garch(1,0) , data=simple_ts_fit_scale, cond.dist="std") 
summary(out.garch6) # garch(1,0)
plot(out.garch6)

out.garch8 <- garchFit(~ arma(1,5) + garch(1,0) , data=simple_ts_fit_scale, cond.dist="std") 
summary(out.garch8) # garch(1,0)
plot(out.garch8) # AIC and BIC back up


out.garch7 <- garchFit(~ arma(1,4) + garch(1,0) , data=simple_ts_fit_scale, cond.dist="std") 
summary(out.garch7) # garch(1,0)
plot(out.garch7)

# I would say overall, I like 2.5, 3, 6 oor 7 is best.
# AIC and BIC prefer 7. So, lets go with that.

my_garch_fit = tibble(date = datagg_short$date, conditional_sd =
    out.garch7@sigma.t, final_residuals = out.garch7@residuals, 
    conditional_var = out.garch7@h.t)


ggplot(my_garch_fit, aes(x=date, y = conditional_sd)) + geom_line() + ggtitle("GARCH Conditional Standard Deviation Estimates") + ylab("Conditional Standard Deviation")
ggsave( paste("GarchSDwithoutTimings.jpg", sep = ""),
    path = paste(my_tex_folder, "weekly", sep = "/"))



ggplot(my_garch_fit, aes(x=date, y = conditional_var)) + geom_line() + ggtitle("GARCH Conditional Variance Estimate") + ylab("Conditional Standard Deviation") 
ggsave( paste("GarchVarwithoutTimings.jpg", sep = ""),
  path = paste(my_tex_folder, "weekly", sep = "/")) 



#probably that spike on the residuals comes from the lack of persistence of the high values!
ggplot(my_garch_fit, aes(x=date, y = final_residuals)) + geom_line() + ggtitle("Final Residuals vs Date")



my_paired_colors = brewer.pal(n = 12, "Paired")
quick_color = my_paired_colors[c(6,5,2,1,10,4,3,7,8)]
ggplot(my_garch_fit, aes(x=date, y = conditional_sd)) + 
  geom_line() + ggtitle("GARCH Conditional Standard Deviation Estimates") +
  geom_vline(data= financial_events, 
    aes( xintercept = date, label = Event_Name, 
      color = Event_Name), wt = 3.5 ) + 
  scale_color_manual(values = quick_color) + ylab("Conditional Standard Deviation")
ggsave( paste("GarchSDwithTimings.jpg", sep = ""),
    path = paste(my_tex_folder, "weekly", sep = "/"))


ggplot(my_garch_fit, aes(x=date, y = conditional_var)) + geom_line() + ggtitle("GARCH Conditional Variance Estimate") + ylab("") + geom_vline(data= financial_events, 
    aes( xintercept = date, label = Event_Name, 
      color = Event_Name), wt = 3.5 ) + 
  scale_color_manual(values = quick_color) + ylab("Conditional Variance")
  
ggsave( paste("GarchVarwithTimings.jpg", sep = ""),
  path = paste(my_tex_folder, "weekly", sep = "/")) 


```


*Another idea I can try is to measure the tail of persistance. for example, looking at the sum as the sequences is 2-15. See the length of the sequence when it peaks and when the peaks occur. Think about if that's meaningful. I wonder if anyone has done a test like this before. I feel its a very natural idea.*



*Also, try the threshhold models. This data looks non-Gaussian and non-Linear. Therefore, a TARMA or SETARMA model may be appropriate*

```{r}
library(pacman)
p_load(tsDyn)

```



# Generate Main Data and Source Functions

```{r}

#############################################
# Data
#############################################

year_pairs = tibble(
    start_year = c(1998, 1998, 2005, 2011, 2016),
    end_year = c(2020, 2004, 2010, 2015, 2020))


############################################
# Functions
############################################

plot_NIC_by_year <- function(start_year, end_year) {
  getPalette = colorRampPalette(brewer.pal(n=9, "Set1")) #can make 11?
  colorCount = end_year - start_year + 1
  pp = ggplot( datagg %>% filter(year>= start_year) %>% filter(year<=end_year) %>% mutate(Year = as_character(year)), aes(x = week, y = NIC/1e6, color = Year)) +
    scale_color_manual(values = getPalette(colorCount)) + 
    geom_point() + geom_line() + ylab("NIC (millions CAD)") +
    ggtitle(paste("Weekly NIC by year from ", start_year, " to ", 
      end_year, sep = "")
    )
}

save_by_year <- function(start_year, end_year) {
  ggsave( paste(
    "NICbyWeek", start_year, "to", end_year, ".jpg", sep = ""),
    path = paste(my_tex_folder, "weekly", sep = "/"))
}

plot_NIC_time_series <- function(start_year, end_year) {
  my_paired_colors = brewer.pal(n = 12, "Paired")
  financial_events_local = financial_events %>% filter(
    year(date)>= start_year) %>% filter(year(date)<=end_year)
  Event_count = nrow(financial_events_local)
  quick_color = my_paired_colors[c(6,5,2,1,10,4,3,7,8)]
  quick_color = quick_color[1:Event_count]
  pp = ggplot( datagg %>% filter(year>= start_year) %>% filter(year<=end_year), aes(x = date, y = NIC/1e6)) +
    geom_point() + geom_smooth(color="grey") + 
    ylab("NIC (Millions CAD)") + 
  ggtitle("NIC Over Time") +
  geom_vline(data= financial_events_local, aes( xintercept = date, label = Event_Name, color = Event_Name), wt = 3.5 ) + 
  scale_color_manual(values = quick_color) + ggtitle(
    paste("Weekly NIC from ", start_year, " to ", end_year, sep = "")
  )
}

save_time_series <- function(start_year, end_year){
    ggsave( paste(
    "NICtimeseries", start_year, "to",  end_year, ".jpg", sep = ""),
    path = paste(my_tex_folder, "weekly", sep = "/"))
}


generate_all_plots <- function(plot_generator) {
  year_pairs =.GlobalEnv$year_pairs 
    #get(year_pairs, envir = .GlobalEnv)
  force(year_pairs)
  
  # environment(plot_generator) = .GlobalEnv
   #my_plots = year_pairs %>% transmute(
   # my_plots= list(plot_generator(begin_year,final_year)))
  my_plot_list = list()
  for (i in 1:nrow(year_pairs)) {
    my_plot_list[[i]] = plot_generator(year_pairs$start_year[i],
      year_pairs$end_year[i])
  }
  my_plot_list
}

print_and_save_them_all = function(my_plot_list, plot_type="Forgot") {
  if (plot_type == "by_year") {
    for (counter in 1:length(my_plot_list)) {
      force(counter)
      print(my_plot_list[[counter]])
      save_by_year(year_pairs$start_year[counter],
        year_pairs$end_year[counter] )
    }  
  } else if (plot_type == "time_series") {
    for (counter in 1:length(my_plot_list)) {
      force(counter)
      print(my_plot_list[[counter]])
      save_time_series(year_pairs$start_year[counter],
        year_pairs$end_year[counter] )
    }  
    
  } else {
    print("Please provide either \"by_year\" or \"time_series\" as a plot type")
  }
}


plot_them_all = function(my_plot_list){
  for (each_plot in my_plot_list) plot(each_plot)
} 


#####################
# Generating Output
####################

by_year_plot = generate_all_plots(plot_NIC_time_series)
time_series_plot =  generate_all_plots(plot_NIC_by_year)


###########
# plot and save
print_and_save_them_all(by_year_plot, plot_type = "by_year")
print_and_save_them_all(time_series_plot, plot_type = "time_series")

# or, a quick view

###########
# generating plots without saving 
plot_them_all(by_year_plot)
plot_them_all(time_series_plot)



quick_plots = generate_all_plots(plot_NIC_by_year)
plot_them_all(quick_plots)


```



```{r extra}
for (each_graph in quick_plots) {
  print(each_graph)
}

pp = plot_NIC_by_year(1998, 2020)
pp
ggsave("NICbyWeekAllyears.jpg", path = paste(my_tex_folder, "weekly", sep = "/"))
pp1 = plot_NIC_by_year(1998, 2004 )
pp2 = plot_NIC_by_year(2005, 2010 )
pp3 = plot_NIC_by_year(2011, 2015)
pp4 = plot_NIC_by_year(2016,2020)
pp1
ggsave("NICbyWeek1998to2004.jpg", path = paste(my_tex_folder, "weekly", sep = "/"))
pp2
ggsave("NICbyWeek2005to2010.jpg", path = paste(my_tex_folder, "weekly", sep = "/"))
pp3
ggsave("NICbyWeek2011to2015.jpg", path = paste(my_tex_folder, "weekly", sep = "/"))
pp4
ggsave("NICbyWeek2015to2020.jpg", path = paste(my_tex_folder, "weekly", sep = "/"))

pp = plot_NIC_time_series(1998, 2020)
pp
ggsave("NICtimeseriesAllyears.jpg", path = paste(my_tex_folder, "weekly", sep = "/"))
pp1 = plot_NIC_time_series(1998, 2004 )
pp2 = plot_NIC_time_series(2005, 2010 )
pp3 = plot_NIC_time_series(2011, 2015)
pp4 = plot_NIC_time_series(2016,2020)
pp1
ggsave("NICtimeseries1998to2004.jpg", path = paste(my_tex_folder, "weekly", sep = "/"))
pp2
ggsave("NICtimeseries2005to2010.jpg", path = paste(my_tex_folder, "weekly", sep = "/"))
pp3
ggsave("NICtimeseries2011to2015.jpg", path = paste(my_tex_folder, "weekly", sep = "/"))
pp4
ggsave("NICtimeseries2015to2020.jpg", path = paste(my_tex_folder, "weekly", sep = "/"))

#plot_generator(start_year, end_year)
 
```

